<!DOCTYPE html> <!--[if lt IE 7]><html class="no-js lt-ie9 lt-ie8 lt-ie7"> <![endif]--> <!--[if (IE 7)&!(IEMobile)]><html class="no-js lt-ie9 lt-ie8"><![endif]--> <!--[if (IE 8)&!(IEMobile)]><html class="no-js lt-ie9"><![endif]--> <!--[if gt IE 8]><!--> <html class="no-js"><!--<![endif]--> <head> <meta charset="UTF-8"> <meta content="text/html; charset=UTF-8" http-equiv="Content-Type"> <meta http-equiv=X-UA-Compatible content="IE=edge,chrome=1"> <title>A Review of "Neural Style Transfer: A Review" - 3 &#8211; JINH-ZERO-PARK</title> <meta name="description" content="Welcome."> <meta name="keywords" content=""> <!-- Twitter Cards --> <meta name="twitter:card" content="summary"> <meta name="twitter:image" content="/assets/img/logo.png"> <meta name="twitter:title" content="A Review of "Neural Style Transfer: A Review" - 3"> <meta name="twitter:description" content="Contents"> <!-- Open Graph --> <meta property="og:locale" content="en_US"> <meta property="og:type" content="article"> <meta property="og:title" content="A Review of "Neural Style Transfer: A Review" - 3"> <meta property="og:description" content="Contents"> <meta property="og:url" content="/nst-review-3/"> <meta property="og:site_name" content="JINH-ZERO-PARK"> <meta property="og:image" content="/assets/img/logo.png"> <link rel="canonical" href="/nst-review-3/"> <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="JINH-ZERO-PARK Feed"> <!-- Handheld --> <meta name="HandheldFriendly" content="True"> <meta name="MobileOptimized" content="320"> <meta name="viewport" content="width=device-width, initial-scale=1.0"> <!-- CSS --> <link rel="stylesheet" href="/assets/css/main.css"> <!-- JS --> <script src="/assets/js/modernizr-3.3.1.custom.min.js"></script> <!-- Favicons --> <link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon-precomposed.png"> <link rel="apple-touch-icon" sizes="72x72" href="/assets/img/favicons/apple-icon-72x72.png"> <link rel="apple-touch-icon" sizes="114x114" href="/assets/img/favicons/apple-icon-114x114.png"> <link rel="apple-touch-icon" sizes="144x144" href="/assets/img/favicons/apple-icon-144x144.png"> <link rel="shortcut icon" type="image/png" href="/favicon.png" /> <link rel="shortcut icon" href="/favicon.ico" /> <!-- Background Image --> <style type="text/css">body {background-image:url(/assets/img/placeholder-big.jpg); background-repeat: no-repeat; background-size: cover; }</style> <!-- Post Feature Image --> </head> <body> <nav id="dl-menu" class="dl-menuwrapper" role="navigation"> <button class="dl-trigger">Open Menu</button> <ul class="dl-menu"> <li><a href="/">Home</a></li> <li> <a href="#">About</a> <ul class="dl-submenu"> <li> <img src="/assets/img/logo.png" alt="JINH-ZERO-PARK photo" class="author-photo"> <h4>JINH-ZERO-PARK</h4> <p>Welcome.</p> </li> <li><a href="/about/"><span class="btn btn-inverse">Learn More</span></a></li> <li> <a href="mailto:jinh0park@naver.com" target="_blank" rel="noopener noreferrer"><i class="fa fa-fw fa-envelope-square"></i> Email</a> </li> <li> <a href="http://instagram.com/jinh0park" target="_blank" rel="noopener noreferrer"><i class="fa fa-fw fa-instagram"></i> Instagram</a> </li> <li> <a href="http://github.com/jinh0park" target="_blank" rel="noopener noreferrer"><i class="fa fa-fw fa-github"></i> Github</a> </li> </ul><!-- /.dl-submenu --> </li> <li> <a href="#">Posts</a> <ul class="dl-submenu"> <li><a href="/posts/">All Posts</a></li> <li><a href="/tags/">All Tags</a></li> </ul> </li> <li><a href="/projects/" >Projects</a></li> </ul><!-- /.dl-menu --> </nav><!-- /.dl-menuwrapper --> <!-- Header --> <header class="header" role="banner"> <div class="wrapper animated fadeIn"> <div class="content"> <div class="post-title "> <h1>A Review of "Neural Style Transfer: A Review" - 3</h1> <h4>24 Aug 2019</h4> <p class="reading-time"> <i class="fa fa-clock-o"></i> Reading time ~5 minutes </p><!-- /.entry-reading-time --> <a class="btn zoombtn" href="/posts/"> <i class="fa fa-chevron-left"></i> </a> </div> <h2 id="contents">Contents</h2> <ul> <li>Image-Optimisation-Based Online Neural Methods <ul> <li>Parametric Neural Methods with Summary Statistics <ul> <li>Gatys et al, “A Neural Algorithm of Artistic Style”, 2015.</li> <li>Li et al, “Demystifying Neural Style Transfer”, 2017.</li> <li>Li et al. “Laplacian-Steered Neural Style Transfer”, 2017.</li> </ul> </li> <li>Non-parametric Neural Methods with MRFs</li> </ul> </li> </ul> <p><img src="/img/posts/nst/taxonomy.PNG" alt="" width="90%" class="center-image" /></p> <p>위 그림에서 볼 수 있듯, NST 알고리즘들은 크게 IOB-IR, MOB-IR로 나눌 수 있다. 이번 글에서는 그 중 IOB-IR 알고리즘들을 대표적인 논문들을 통해 알아본다.</p> <h2 id="image-optimisation-based-online-neural-methods">Image-Optimisation-Based Online Neural Methods</h2> <h3 id="parametric-neural-methods-with-summary-statistics">Parametric Neural Methods with Summary Statistics</h3> <p>Parametric IOB-IR 알고리즘의 핵심은 생성할 이미지의 Style Information은 Style Image에 맞추고, Content Image는 Content Image에 맞추는 것이다. 그에 따라 각각의 “Information”을 어떻게 추출할지에 대해 주로 연구가 되어왔다.</p> <hr /> <h4 id="gatys-et-al-a-neural-algorithm-of-artistic-style-2015">Gatys et al, “A Neural Algorithm of Artistic Style”, 2015.</h4> <p><a href="https://arxiv.org/abs/1508.06576">Arxiv Link</a></p> <p><img src="/img/posts/nst/gatys_1.PNG" alt="" width="90%" class="center-image" /></p> <p>NST의 효시격 논문인 이 논문에서는 \(I_{output}\), \(I_{content}\), \(I_{style}\) 세 이미지에 대해 다음과 같은 Loss Function을 정의한 뒤, 이 Loss를 최소화시키는 방향으로 \(I_{output}\) 를 optimize한다.</p> <p>\[L_{total} = \alpha L_{content} + \beta L_{style} \]</p> <p>\(L_{content}\) 와 \(L_{style}\) 은 다음과 같이 정의된다.</p> <script type="math/tex; mode=display">L_{content} = {1 \over 2} \sum(F_l - P_l)^2</script> <script type="math/tex; mode=display">L_{style} = \sum{1 \over {4N_l^2M_l^2}}(Gram(F_l) - Gram(P_l))^2</script> <ul> <li>\(F_l\): \(I_{output}\) 를 VGG Network의 통과시켰을 때, \(l\)번째 레이어의 feature map</li> <li>\(P_l\): \(I_{content}\) 를 VGG Network의 통과시켰을 때, \(l\)번째 레이어의 feature map</li> <li>\(S_l\): \(I_{style}\) 를 VGG Network의 통과시켰을 때, \(l\)번째 레이어의 feature map</li> </ul> <p>\(Gram(X)\) 는 주어진 행렬 X에 대한 Gram matrix를 의미하며, feature map의 경우 \(C \times W \times H\) 3-dim array이기 때문에 \(C(=N_l) \times HW(=M_l)\) 로 reshape하여 Gram matrix를 계산한다. 이때, 행렬 X에 대한 Gram matrix는 다음과 같다.</p> <script type="math/tex; mode=display">G_{ij} = \sum_k X_{ik}X_{jk}</script> <p>더 쉽게 표현하면, \(Gram(X) = X \cdot X^T\) 이다.</p> <p>이 논문에서는 \(l\), 즉 각 Loss를 계산할 때 어떤 layer를 선택했는지가 중요한 요소라고 한다. 기본적으로 \(L_{content}\) 를 계산할때는 \(conv4_2\), \(L_{style}\) 에서는 \({conv1_1, conv2_1, conv3_1, conv4_1, conv5_1}\) 을 사용했으며(relu까지 포함), 네트워크는 pretrained VGG19를 사용하며, 이 네트워크는 업데이트되지 않고 오직 \(I_{output}\) 만 업데이트된다.</p> <p>\(\alpha\) 와 \(\beta\) 의 비율을 어떻게 하느냐에 따라 \(I_{output}\) 이 \(I_{content}\) 에 가까운지, \(I_{style}\) 에 가까운지가 결정되는데, \(\alpha / \beta\) 비율을 크게할 수록 이미지의 윤곽이 살고 작아질수록 스타일이 강해지는 것을 볼 수 있다.</p> <p><img src="/img/posts/nst/gatys_2.PNG" alt="" width="90%" class="center-image" /> 왼쪽부터 \(\alpha / \beta = 10^{-5}, 10^{-4}, 10^{-3}, 10^{-2}\) {:.caption}</p> <p>그 외 특이 사항으로는, VGG19 Network은 원래 Max pooling을 사용하나 Average pooling으로 이를 대체하였을 때 더 좋은 이미지 결과가 나왔다고 한다.</p> <p><strong>Contributions</strong></p> <ul> <li>Ground truth 없이 style transfer를 수행</li> <li>Style image에 특별한 제한을 두지 않고도 수행이 가능</li> </ul> <p><strong>Limits</strong></p> <ul> <li>Content image의 fine structure와 detail을 표현하지 못함 <ul> <li>CNN의 feature extractor가 low-level feature를 잃어버리기 때문</li> </ul> </li> <li>Photo-realistic한 style transfer는 불가능</li> <li>다양한 형태의 획과 칠을 표현하지 못하고, content image의 depth information을 잃어버림 (depth information이 무엇인지는 더 찾아 보아야 할 듯)</li> <li>Gram matrix가 왜 Style representation을 나타내는지 자세히 밝히지 못함</li> </ul> <p>Gatys의 알고리즘은 Baseline으로 주로 사용되기 때문에 다소 길게 요약하였다.</p> <hr /> <h4 id="li-et-al-demystifying-neural-style-transfer-2017">Li et al, “Demystifying Neural Style Transfer”, 2017.</h4> <p>\(I_{output}\) 과 \(I_{style}\) 의 feature map에 Gram matrix를 씌운 값의 차이를 최소화 시키는게 왜 두 이미지의 Style을 비슷하게 만들까? 이에 대해 수학적으로 분석하고, 더 나아가 Gram matrix 외에도 다른 방법론을 제안한 논문이 Li의 논문 <em>Demystifying Neural Style Transfer</em> 이다. Gram matrix의 역할이 \(I_{output}\) 과 \(I_{style}\) 의 feature map의 distribution을 비슷하게 만드는 것임을 수학적으로 증명했다.</p> <p>자세히 말하자면 MMD(Maximum Mean Discrepancy)를 최소화 시킴을 증명했는데, MMD는 두 분포 사이의 차이를 나타내는 측도로 KL-Divergence 등과 비슷한 맥락에 속한다. 이를 아주 간단히 설명하면 다음과 같다. 어떤 두 분포 \(p\) 와 \(q\) 가 있을 때, 이 둘이 서로 같을 필요 충분 조건은 임의의 함수 \(f\)에 대해 f(sample)의 기댓값이 같아야 한다는 것이다. 따라서, 이 두 기댓값의 차이를 MMD로 정의하며, 이를 두 분포 \(p\) 와 \(q\) 의 차이로 정의한다.(엄밀한 정리는 아래 사진에 있으며, 도움이 될 자료도 <a href="https://www.stat.cmu.edu/~ryantibs/journalclub/mmd.pdf">첨부</a>한다.)</p> <p>여하튼 MMD를 정의하기 위해서는 함수 \(f\)(=커널 $k$)가 정의되어야하는데, Gram matrix는 이 kernel이 qudratic polynomial인 경우이며, 따라서 Gram matrix를 사용하는 것은 \(I_{output}\) 과 \(I_{style}\) 간의 MMD를 줄이는 효과를 가져왔다는 것이다.</p> <p>MMD만 같게 하면 Style을 비슷하게 할 수 있다는 것에 착안해 다른 kernel(linear, gaussian, BN)들을 사용해 이들 경우에도 Style transfer가 잘 구현됨을 보였다. 이를 통해, DL에서 중요한 영역인 interpretation을 NST에 대해서도 설명할 수 있게 되었다는 의미가 있다.</p> <p><img src="/img/posts/nst/demyst.PNG" alt="" width="90%" class="center-image" /></p> <p><strong>Contributions</strong></p> <ul> <li>Gatys의 알고리즘이 어떤 원리로 작동하는지 수학적으로 증명</li> <li>Image feature의 distribution 차이를 줄이는 것이 stylization의 한 방법임을 제시</li> </ul> <p><strong>Limits</strong></p> <ul> <li>Gatys의 알고리즘이 가지고 있는 문제점들을 해결하지는 못함</li> </ul> <p><img src="/img/posts/nst/mmd.PNG" alt="" width="90%" class="center-image" /> <em>The definition of MMD</em></p> <hr /> <h4 id="li-et-al-laplacian-steered-neural-style-transfer-2017">Li et al. “Laplacian-Steered Neural Style Transfer”, 2017.</h4> <p><img src="/img/posts/nst/laplacian.PNG" alt="" width="90%" class="center-image" /></p> <p>Gatys의 알고리즘은 Content Image의 형태를 왜곡하는 현상이 있었다. 이를 보완하기 위해 Li는 \(L_{style}\), \(L_{content}\) 에 이어 Laplacian Loss $L_{laplacian}$ 을 추가했다.</p> <p><img src="/img/posts/nst/lap_example.PNG" alt="" width="90%" class="center-image" /></p> <p>원본 이미지(좌)를 Laplacian filter에 통과 시키면 오른쪽 그림처럼 Edge 부분만 남게 되는데, \(I_{output}\) 과 \(I_{content}\) 의 Laplacian filter 통과 값의 차이를 추가 Loss Term으로 추가했으며, 식으로 표현하면 다음과 같다($D$는 Laplacian Operator).</p> <script type="math/tex; mode=display">L_{laplacian} = \sum_{i, j}(D(I_{content}) - D(I_{output}))_{ij}^2</script> <p>이를 통해 Content Image의 형태를 잘 보존할 수 있게 되었다고한다.</p> <hr /> <h3 id="non-parametric-neural-methods-with-mrfs">Non-parametric Neural Methods with MRFs</h3> <h4 id="li-et-al-combining-markov-random-fields-and-convolutional-neural-networks-for-image-synthesis-2016">Li et al. “Combining Markov Random Fields and Convolutional Neural Networks for Image Synthesis”, 2016.</h4> <p><em>NST 관련 논문 저자에 이 “Li”라는 이름이 자주 등장해서 NST 분야의 권위자인가 싶었는데, 알고보니 성씨만 같고 다 다른 사람이었다…</em></p> <p>이 논문에서 Style Transfer를 적용하는 방법은 다음과 같다.</p> <ol> <li>\(I_{style}\) 과 \(I_{output}\) 을 pretrained VGG19 Network에 통과시킨다.</li> <li>생성된 각각의 feature map \(F_s\), \(F_o\)를 \(k * k * C\) patch로 자른다.</li> <li>각각의 patch set에 속해있는 patch를 서로 일대일 대응 시키는데, 이 때 patch 쌍의 Normalized cross correlation이 가장 작도록한다(이 과정에서도 Network가 쓰인다).</li> <li>쌍을 이룬 style feature patch들의 L2 loss와 \(L_{content}\) 가 최소가 되도록 Image를 optimize한다.</li> </ol> <p>여기서 3번에서의 Patch를 서로 대응 시키는 과정을 Patch Matching이라고 하는데, 이 논문에서는 Patch Matching 과정에 MRF prior를 도입하여 성능을 개선시켰다고 한다. 하지만 MRF에 대해 아직 공부를 하지 못해서 자세히는 모르겠다.</p> <p><img src="/img/posts/nst/mrfnst.PNG" alt="" width="70%" class="center-image" /></p> <p>Patch matching은 \(I_{style}\), \(I_{content}\) 의 비슷한 부분을 매칭하여 stylize를 하는 효과를 가져오기 때문에, Content Image와 Style Image가 비슷한 모양을 가지고 있으면 뛰어난 성능을 보여주며, 특히 photorealistic한 경우에 image distortion이 적게 나타나 현실감있는 이미지를 생성한다. 하지만 같은 이유로 Content Image와 Style Image의 모양이 크게 다르면 잘 작동하지 않는다(위 사진의 두번째 행 참고).</p> <p>참고로, 이 논문에서 Patch matching을 어떻게 구현했는지 아무리 찾아보려고 해도 논문 상에는 additional conv layer를 사용했다는 말 외에는 별 다른 설명이 없었다. Neural Matching이 원래부터 있던 알고리즘이기 때문에 생략한 것 같기도 한데… MRF NST 알고리즘을 공부하기 위해서는 MRF나 Neural Matching 등 사전 지식에 대한 공부가 많이 필요할 것 같다.</p> <hr /> <h2 id="summary">Summary</h2> <p>NST를 IOB-IR과 MOB-IR로 나누어 볼 때, 비교적 먼저 등장한 개념인 IOB-IR에 대표적인 논문 몇 가지를 살펴 보았다. Gatys의 알고리즘을 Baseline으로 이를 개선하려는 여러 시도들이 있었고, 주로 Loss term을 새로 추가, 수정 하는 방식으로 연구가 되어왔다.</p> <p>다음 리뷰에서는 IOB-IR의 가장 큰 단점인 Inference Time을 개선할 수 있는 MOB-IR 카테고리에 대해 논문 리뷰와 함께 공부해 볼 예정이다.</p> <div class="entry-meta"> <br> <hr> <span class="entry-tags"></span> <!-- <span class="social-share"> <a href="https://www.facebook.com/sharer/sharer.php?u=/nst-review-3/" title="Share on Facebook" class="tag"> <span class="term"><i class="fa fa-facebook-square"></i> Share</span> </a> <a href="https://twitter.com/intent/tweet?text=/nst-review-3/" title="Share on Twitter" class="tag"> <span class="term"><i class="fa fa-twitter-square"></i> Tweet</span> </a> <a href="https://plus.google.com/share?url=/nst-review-3/" title="Share on Google+" class="tag"> <span class="term"><i class="fa fa-google-plus-square"></i> +1</span> </a> </span> --> <div style="clear:both"></div> </div> </div> </div> <section id="disqus_thread" class="animated fadeInUp"></section><!-- /#disqus_thread --> </header> <!-- JS --> <script src="/assets/js/jquery-1.12.0.min.js"></script> <script src="/assets/js/jquery.dlmenu.min.js"></script> <script src="/assets/js/jquery.goup.min.js"></script> <script src="/assets/js/jquery.magnific-popup.min.js"></script> <script src="/assets/js/jquery.fitvid.min.js"></script> <script src="/assets/js/scripts.js"></script> <script type="text/javascript"> var disqus_shortname = 'jinh0park'; (function() { var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true; dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js'; (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq); })(); (function () { var s = document.createElement('script'); s.async = true; s.type = 'text/javascript'; s.src = '//' + disqus_shortname + '.disqus.com/count.js'; (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s); }()); </script> <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript> <!-- MathJax --> <script async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script> </body> </html>
